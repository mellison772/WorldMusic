{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9729293f-23b1-4288-98cc-143ea0c60d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load libraries\n",
    "import pandas as pd\n",
    "import geopy as geo\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from geopy.distance import geodesic\n",
    "from geopy.geocoders import Nominatim\n",
    "#from tqdm import tqdm  #NOT NEEDED FOR GRADING. just a progress bar for a long step\n",
    "\n",
    "#Load Data\n",
    "df = pd.read_csv('default_features_1059_tracks.txt', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c4d4e06-2bc8-421a-aece-0700f18c5fb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.161286</td>\n",
       "      <td>7.835325</td>\n",
       "      <td>2.911583</td>\n",
       "      <td>0.984049</td>\n",
       "      <td>-1.499546</td>\n",
       "      <td>-2.094097</td>\n",
       "      <td>0.576000</td>\n",
       "      <td>-1.205671</td>\n",
       "      <td>1.849122</td>\n",
       "      <td>-0.425598</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.504263</td>\n",
       "      <td>0.351267</td>\n",
       "      <td>-1.018726</td>\n",
       "      <td>-0.174878</td>\n",
       "      <td>-1.089543</td>\n",
       "      <td>-0.668840</td>\n",
       "      <td>-0.914772</td>\n",
       "      <td>-0.836250</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>-47.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.225763</td>\n",
       "      <td>-0.094169</td>\n",
       "      <td>-0.603646</td>\n",
       "      <td>0.497745</td>\n",
       "      <td>0.874036</td>\n",
       "      <td>0.290280</td>\n",
       "      <td>-0.077659</td>\n",
       "      <td>-0.887385</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>-0.093963</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.495712</td>\n",
       "      <td>-0.465077</td>\n",
       "      <td>-0.157861</td>\n",
       "      <td>-0.157189</td>\n",
       "      <td>0.380951</td>\n",
       "      <td>1.088478</td>\n",
       "      <td>-0.123595</td>\n",
       "      <td>1.391141</td>\n",
       "      <td>14.91</td>\n",
       "      <td>-23.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.692525</td>\n",
       "      <td>-0.517801</td>\n",
       "      <td>-0.788035</td>\n",
       "      <td>1.214351</td>\n",
       "      <td>-0.907214</td>\n",
       "      <td>0.880213</td>\n",
       "      <td>0.406899</td>\n",
       "      <td>-0.694895</td>\n",
       "      <td>-0.901869</td>\n",
       "      <td>-1.701574</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.637167</td>\n",
       "      <td>0.147260</td>\n",
       "      <td>0.217914</td>\n",
       "      <td>2.718442</td>\n",
       "      <td>0.972919</td>\n",
       "      <td>2.081069</td>\n",
       "      <td>1.375763</td>\n",
       "      <td>1.063847</td>\n",
       "      <td>12.65</td>\n",
       "      <td>-8.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.735562</td>\n",
       "      <td>-0.684055</td>\n",
       "      <td>2.058215</td>\n",
       "      <td>0.716328</td>\n",
       "      <td>-0.011393</td>\n",
       "      <td>0.805396</td>\n",
       "      <td>1.497982</td>\n",
       "      <td>0.114752</td>\n",
       "      <td>0.692847</td>\n",
       "      <td>0.052377</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178325</td>\n",
       "      <td>-0.065059</td>\n",
       "      <td>-0.724247</td>\n",
       "      <td>-1.020687</td>\n",
       "      <td>-0.751380</td>\n",
       "      <td>-0.385005</td>\n",
       "      <td>-0.012326</td>\n",
       "      <td>-0.392197</td>\n",
       "      <td>9.03</td>\n",
       "      <td>38.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.570272</td>\n",
       "      <td>0.273157</td>\n",
       "      <td>-0.279214</td>\n",
       "      <td>0.083456</td>\n",
       "      <td>1.049331</td>\n",
       "      <td>-0.869295</td>\n",
       "      <td>-0.265858</td>\n",
       "      <td>-0.401676</td>\n",
       "      <td>-0.872639</td>\n",
       "      <td>1.147483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.919463</td>\n",
       "      <td>-0.667912</td>\n",
       "      <td>-0.820172</td>\n",
       "      <td>-0.190488</td>\n",
       "      <td>0.306974</td>\n",
       "      <td>0.119658</td>\n",
       "      <td>0.271838</td>\n",
       "      <td>1.289783</td>\n",
       "      <td>34.03</td>\n",
       "      <td>-6.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>0.399577</td>\n",
       "      <td>0.310805</td>\n",
       "      <td>-0.039326</td>\n",
       "      <td>-0.111546</td>\n",
       "      <td>0.304586</td>\n",
       "      <td>-0.943453</td>\n",
       "      <td>0.114960</td>\n",
       "      <td>-0.335898</td>\n",
       "      <td>0.826753</td>\n",
       "      <td>-0.393786</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.558717</td>\n",
       "      <td>0.998897</td>\n",
       "      <td>-0.106835</td>\n",
       "      <td>1.526307</td>\n",
       "      <td>0.646088</td>\n",
       "      <td>2.467278</td>\n",
       "      <td>1.867699</td>\n",
       "      <td>1.719302</td>\n",
       "      <td>-6.17</td>\n",
       "      <td>35.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1055</th>\n",
       "      <td>1.640386</td>\n",
       "      <td>1.306224</td>\n",
       "      <td>0.192745</td>\n",
       "      <td>-1.816855</td>\n",
       "      <td>-1.311906</td>\n",
       "      <td>-2.128963</td>\n",
       "      <td>-1.875967</td>\n",
       "      <td>0.094232</td>\n",
       "      <td>-1.429742</td>\n",
       "      <td>0.873777</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223143</td>\n",
       "      <td>-0.032425</td>\n",
       "      <td>0.226782</td>\n",
       "      <td>0.182107</td>\n",
       "      <td>0.517466</td>\n",
       "      <td>1.126762</td>\n",
       "      <td>2.220671</td>\n",
       "      <td>4.422651</td>\n",
       "      <td>11.55</td>\n",
       "      <td>104.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1056</th>\n",
       "      <td>-0.772360</td>\n",
       "      <td>-0.670596</td>\n",
       "      <td>-0.840420</td>\n",
       "      <td>-0.832105</td>\n",
       "      <td>0.277346</td>\n",
       "      <td>1.152162</td>\n",
       "      <td>0.241470</td>\n",
       "      <td>0.229092</td>\n",
       "      <td>0.019036</td>\n",
       "      <td>-0.068804</td>\n",
       "      <td>...</td>\n",
       "      <td>0.449239</td>\n",
       "      <td>-0.965270</td>\n",
       "      <td>-0.590039</td>\n",
       "      <td>-0.804297</td>\n",
       "      <td>0.044170</td>\n",
       "      <td>-0.718175</td>\n",
       "      <td>-0.983640</td>\n",
       "      <td>-0.573822</td>\n",
       "      <td>41.33</td>\n",
       "      <td>19.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>-0.996965</td>\n",
       "      <td>-1.099395</td>\n",
       "      <td>3.515274</td>\n",
       "      <td>-0.508185</td>\n",
       "      <td>-1.102654</td>\n",
       "      <td>0.192081</td>\n",
       "      <td>0.069821</td>\n",
       "      <td>0.264674</td>\n",
       "      <td>-0.411533</td>\n",
       "      <td>0.501164</td>\n",
       "      <td>...</td>\n",
       "      <td>1.941398</td>\n",
       "      <td>1.769292</td>\n",
       "      <td>0.738616</td>\n",
       "      <td>1.240377</td>\n",
       "      <td>-0.546002</td>\n",
       "      <td>-0.137473</td>\n",
       "      <td>-0.781036</td>\n",
       "      <td>-0.832167</td>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1058</th>\n",
       "      <td>-0.150911</td>\n",
       "      <td>-0.094333</td>\n",
       "      <td>-0.568885</td>\n",
       "      <td>-0.614652</td>\n",
       "      <td>0.332477</td>\n",
       "      <td>-0.954948</td>\n",
       "      <td>-1.527722</td>\n",
       "      <td>-1.591471</td>\n",
       "      <td>-3.678713</td>\n",
       "      <td>-5.930209</td>\n",
       "      <td>...</td>\n",
       "      <td>5.121875</td>\n",
       "      <td>4.103031</td>\n",
       "      <td>3.673086</td>\n",
       "      <td>0.960420</td>\n",
       "      <td>1.067164</td>\n",
       "      <td>5.244305</td>\n",
       "      <td>2.506568</td>\n",
       "      <td>1.462580</td>\n",
       "      <td>54.68</td>\n",
       "      <td>25.31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1059 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             1         2         3         4         5         6         7  \\\n",
       "0     7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
       "1     0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
       "2    -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
       "3    -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
       "4     0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1054  0.399577  0.310805 -0.039326 -0.111546  0.304586 -0.943453  0.114960   \n",
       "1055  1.640386  1.306224  0.192745 -1.816855 -1.311906 -2.128963 -1.875967   \n",
       "1056 -0.772360 -0.670596 -0.840420 -0.832105  0.277346  1.152162  0.241470   \n",
       "1057 -0.996965 -1.099395  3.515274 -0.508185 -1.102654  0.192081  0.069821   \n",
       "1058 -0.150911 -0.094333 -0.568885 -0.614652  0.332477 -0.954948 -1.527722   \n",
       "\n",
       "             8         9        10  ...        61        62        63  \\\n",
       "0    -1.205671  1.849122 -0.425598  ... -1.504263  0.351267 -1.018726   \n",
       "1    -0.887385  0.432062 -0.093963  ... -0.495712 -0.465077 -0.157861   \n",
       "2    -0.694895 -0.901869 -1.701574  ... -0.637167  0.147260  0.217914   \n",
       "3     0.114752  0.692847  0.052377  ... -0.178325 -0.065059 -0.724247   \n",
       "4    -0.401676 -0.872639  1.147483  ... -0.919463 -0.667912 -0.820172   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1054 -0.335898  0.826753 -0.393786  ... -0.558717  0.998897 -0.106835   \n",
       "1055  0.094232 -1.429742  0.873777  ...  0.223143 -0.032425  0.226782   \n",
       "1056  0.229092  0.019036 -0.068804  ...  0.449239 -0.965270 -0.590039   \n",
       "1057  0.264674 -0.411533  0.501164  ...  1.941398  1.769292  0.738616   \n",
       "1058 -1.591471 -3.678713 -5.930209  ...  5.121875  4.103031  3.673086   \n",
       "\n",
       "            64        65        66        67        68  latitude  longitude  \n",
       "0    -0.174878 -1.089543 -0.668840 -0.914772 -0.836250    -15.75     -47.95  \n",
       "1    -0.157189  0.380951  1.088478 -0.123595  1.391141     14.91     -23.51  \n",
       "2     2.718442  0.972919  2.081069  1.375763  1.063847     12.65      -8.00  \n",
       "3    -1.020687 -0.751380 -0.385005 -0.012326 -0.392197      9.03      38.74  \n",
       "4    -0.190488  0.306974  0.119658  0.271838  1.289783     34.03      -6.85  \n",
       "...        ...       ...       ...       ...       ...       ...        ...  \n",
       "1054  1.526307  0.646088  2.467278  1.867699  1.719302     -6.17      35.74  \n",
       "1055  0.182107  0.517466  1.126762  2.220671  4.422651     11.55     104.91  \n",
       "1056 -0.804297  0.044170 -0.718175 -0.983640 -0.573822     41.33      19.80  \n",
       "1057  1.240377 -0.546002 -0.137473 -0.781036 -0.832167     54.68      25.31  \n",
       "1058  0.960420  1.067164  5.244305  2.506568  1.462580     54.68      25.31  \n",
       "\n",
       "[1059 rows x 70 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "21fe8c3a-4458-4b7d-b71e-548e3b34bef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create predictive features and target feature\n",
    "X = df.drop(['longitude', 'latitude'], axis=1)\n",
    "y = df[['longitude', 'latitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e954d8f-9819-484b-a032-fa44271b91ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Feature  Importance\n",
      "4        5    0.076876\n",
      "19      20    0.051632\n",
      "54      55    0.032317\n",
      "3        4    0.029294\n",
      "38      39    0.029271\n",
      "20      21    0.025269\n",
      "8        9    0.024500\n",
      "7        8    0.024146\n",
      "21      22    0.023693\n",
      "55      56    0.022190\n",
      "22      23    0.021924\n",
      "37      38    0.019833\n",
      "53      54    0.019720\n",
      "57      58    0.018916\n",
      "51      52    0.018230\n",
      "35      36    0.016656\n",
      "52      53    0.016597\n",
      "24      25    0.016279\n",
      "43      44    0.015433\n",
      "39      40    0.015256\n",
      "36      37    0.015011\n",
      "1        2    0.014641\n",
      "26      27    0.014367\n",
      "56      57    0.014209\n",
      "17      18    0.014092\n",
      "6        7    0.014025\n",
      "25      26    0.013350\n",
      "44      45    0.012930\n",
      "59      60    0.012454\n",
      "5        6    0.012107\n"
     ]
    }
   ],
   "source": [
    "#Using Random Forest to get feature importance\n",
    "\n",
    "#Specify Regressor\n",
    "model = RandomForestRegressor(random_state=77)\n",
    "\n",
    "#K Folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=77)\n",
    "feature_importances = []\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    feature_importances.append(model.feature_importances_)\n",
    "\n",
    "#AVG importance scores from each fold\n",
    "mean_importances = np.mean(feature_importances, axis=0)\n",
    "\n",
    "#Data frame for comparison\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': mean_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "print(importance_df.head(30))\n",
    "#the far left is just the index number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6832c7b-6d2d-4a53-ad55-be9f08290e39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA for features with importance >0.015\n",
    "pca = PCA(n_components = 20)\n",
    "pca.fit(X)\n",
    "\n",
    "#Make principal components\n",
    "X_pca = pca.transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f27530-aec6-4196-84cf-c02bfbe5415c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This cell is from ChatGPT cause I couldn't figure out how to actually use the PCA\n",
    "#Honesty is the best policy \n",
    "\n",
    "# Set a threshold for high loadings\n",
    "loading_threshold = 0.3  # Adjust this based on your analysis\n",
    "\n",
    "# Get the absolute loadings for selected components\n",
    "important_loadings = loadings[selected_pcs].abs()\n",
    "\n",
    "# Identify columns that exceed the loading threshold in any selected component\n",
    "predictive_columns = important_loadings[(important_loadings > loading_threshold).any(axis=1)].index\n",
    "\n",
    "# Get the most predictive columns\n",
    "X_predictive = X[predictive_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65067aea-7dcf-41a7-a7e7-09d631fc1146",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest Regression\n",
    "\n",
    "#Train/Test Split (used for all regressors)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_predictive, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#Specify regressor (77 for my soccer # :) )\n",
    "model_rf = MultiOutputRegressor(RandomForestRegressor(random_state=77))\n",
    "\n",
    "#Actually train\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = model_rf.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"Mean Squared Error for Latitude: {mse[0]}\")\n",
    "print(f\"Mean Squared Error for Longitude: {mse[1]}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"R^2 for Latitude: {r2[0]}\")\n",
    "print(f\"R^2 for Longitude: {r2[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3165b01-4e7f-4d11-bae0-0083d63a5295",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify and train\n",
    "model_lr = MultiOutputRegressor(LinearRegression())\n",
    "model_lr.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = model_lr.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"Mean Squared Error for Latitude: {mse[0]}\")\n",
    "print(f\"Mean Squared Error for Longitude: {mse[1]}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"R^2 for Latitude: {r2[0]}\")\n",
    "print(f\"R^2 for Longitude: {r2[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f05143-4e29-4181-9915-41c9b3929269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify and train\n",
    "model_kn = MultiOutputRegressor(KNeighborsRegressor(n_neighbors=5))\n",
    "model_kn.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = model_kn.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"Root Mean Squared Error for Latitude: {np.sqrt(mse[0])}\")\n",
    "print(f\"Mean Squared Error for Longitude: {mse[1]}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"R^2 for Latitude: {r2[0]}\")\n",
    "print(f\"R^2 for Longitude: {r2[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa83c2fb-312a-4d59-b568-0238aa86b2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify and train\n",
    "model_gb = MultiOutputRegressor(GradientBoostingRegressor(random_state=77))\n",
    "model_gb.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = model_gb.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"Mean Squared Error for Latitude: {mse[0]}\")\n",
    "print(f\"Mean Squared Error for Longitude: {mse[1]}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"R^2 for Latitude: {r2[0]}\")\n",
    "print(f\"R^2 for Longitude: {r2[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6527175-b10f-426e-9938-3634a642861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify and train\n",
    "model_mlp = MultiOutputRegressor(MLPRegressor(hidden_layer_sizes=(200,200,100), max_iter=1000, random_state=77))\n",
    "model_mlp.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = model_mlp.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "mse = mean_squared_error(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"Mean Squared Error for Latitude: {mse[0]}\")\n",
    "print(f\"Mean Squared Error for Longitude: {mse[1]}\")\n",
    "\n",
    "r2 = r2_score(y_test, y_pred, multioutput='raw_values')\n",
    "print(f\"R^2 for Latitude: {r2[0]}\")\n",
    "print(f\"R^2 for Longitude: {r2[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a70414d-55d4-465e-a14b-eab551b1e273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Distance Error: 3781.41 km\n",
      "     Actual Latitude  Actual Longitude  Predicted Latitude  \\\n",
      "0              38.74              9.03           14.975827   \n",
      "1              69.21             41.26           18.589968   \n",
      "2              26.10             44.41           31.607073   \n",
      "3              26.10             44.41           28.838263   \n",
      "4              26.10             44.41           26.335484   \n",
      "..               ...               ...                 ...   \n",
      "206           139.71             35.70           25.145962   \n",
      "207            -0.12             52.50           10.469518   \n",
      "208            44.78             41.71           38.630822   \n",
      "209            35.74             -6.17           20.237910   \n",
      "210            19.80             41.33           32.479003   \n",
      "\n",
      "     Predicted Longitude  Distance (km)  \n",
      "0              -4.669355    4765.351291  \n",
      "1              21.704878    5146.337336  \n",
      "2              35.595534    1645.023318  \n",
      "3              40.481171    2147.211749  \n",
      "4              55.909042    3338.960992  \n",
      "..                   ...            ...  \n",
      "206            56.077326    7882.936822  \n",
      "207            -2.471513    4666.018612  \n",
      "208            46.933616     387.976053  \n",
      "209            37.125788    2924.910018  \n",
      "210            46.169375    2534.291154  \n",
      "\n",
      "[211 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Regression 2 electric bugaloo, now featuring distances, K-folds, and Grid Search\n",
    "#Random Forest\n",
    "#I commented out the grid search stuff after I got my hyperparamters\n",
    "\n",
    "# Hyperparameter grid \n",
    "#param_grid = {\n",
    "    #'n_estimators': [25, 50, 100, 150],\n",
    "    #'max_depth': [5, 10, 15, 20],\n",
    "    #'min_samples_split': [2, 5, 10],\n",
    "    #'min_samples_leaf': [2, 4, 6]\n",
    "#}\n",
    "#distances_all_splits = []\n",
    "\n",
    "#Train/test\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=77)\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    " # Initialize regressor with hyperparams\n",
    "regressor = RandomForestRegressor(max_depth = 20, min_samples_leaf = 2, min_samples_split = 2, n_estimators = 100, random_state=77)\n",
    "regressor.fit(X_train, y_train)\n",
    "    #base_regressor = RandomForestRegressor(random_state=77)\n",
    "\n",
    "    # Perform grid search\n",
    "    #grid_search = GridSearchCV(\n",
    "        #estimator=base_regressor,\n",
    "        #param_grid=param_grid,\n",
    "        #scoring='neg_mean_squared_error',\n",
    "        #cv=3,\n",
    "        #n_jobs=-1\n",
    "    #)\n",
    "    #grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Use the best estimator\n",
    "    #best_regressor = grid_search.best_estimator_\n",
    "\n",
    "#Predict\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "#Calculate distances\n",
    "distances = []\n",
    "for actual, predicted in zip(y_test.values, y_pred):\n",
    "    actual_coords = tuple(actual) \n",
    "    predicted_coords = tuple(predicted) \n",
    "    distance = geodesic(actual_coords, predicted_coords).kilometers\n",
    "    distances.append(distance)\n",
    "    #distances_all_splits.append(distances)\n",
    "\n",
    "#print(f\"Best hyperparameters: {grid_search.best_params_}\")\n",
    "# Output: Best hyperparameters: {'max_depth': 20, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
    "#DataFrame for viewing pleasure\n",
    "results = pd.DataFrame({\n",
    "    'Actual Latitude': y_test['latitude'].values,\n",
    "    'Actual Longitude': y_test['longitude'].values,\n",
    "    'Predicted Latitude': y_pred[:, 0],\n",
    "    'Predicted Longitude': y_pred[:, 1],\n",
    "    'Distance (km)': distances\n",
    "})\n",
    "\n",
    "#Evaluate\n",
    "print(f\"Mean Distance Error: {np.mean(distances):.2f} km\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a742cbc2-4f4e-40b7-963e-61c66c830a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Distance Error: 3773.85 km\n",
      "     Actual Latitude  Actual Longitude  GBR Latitude  GBR Longitude  \\\n",
      "0               9.03             38.74     18.018115     -16.546236   \n",
      "1              41.26             69.21     12.289033       8.519622   \n",
      "2              44.41             26.10     39.750153      32.068618   \n",
      "3              44.41             26.10     31.358596      30.485784   \n",
      "4              44.41             26.10     39.041594      50.239472   \n",
      "..               ...               ...           ...            ...   \n",
      "206            35.70            139.71     27.336979      39.182597   \n",
      "207            52.50             -0.12     22.382138      14.109491   \n",
      "208            41.71             44.78     41.002584      59.463274   \n",
      "209            -6.17             35.74     15.501280      43.801969   \n",
      "210            41.33             19.80     26.650248      35.972790   \n",
      "\n",
      "     GBR Distance (km)  \n",
      "0          6045.960482  \n",
      "1          6676.172472  \n",
      "2           715.024318  \n",
      "3          1498.528278  \n",
      "4          2086.409802  \n",
      "..                 ...  \n",
      "206        9154.958279  \n",
      "207        3557.362851  \n",
      "208        1229.717078  \n",
      "209        2556.310380  \n",
      "210        2202.438590  \n",
      "\n",
      "[211 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "\n",
    "#Train/test split\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=77)\n",
    "\n",
    "for train_index, test_index in kf.split(df):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "#Specify Regressor\n",
    "base_regressor = GradientBoostingRegressor(n_estimators=150, learning_rate=0.1, random_state=77)\n",
    "multi_output_regressor = MultiOutputRegressor(base_regressor)\n",
    "\n",
    "#Predict\n",
    "multi_output_regressor.fit(X_train, y_train)\n",
    "y_pred = multi_output_regressor.predict(X_test)\n",
    "\n",
    "#Predict, but also keep predictions in valid lat/lon ranges \n",
    "y_pred[:, 0] = np.clip(y_pred[:, 0], -90, 90)  # Latitude\n",
    "y_pred[:, 1] = np.clip(y_pred[:, 1], -180, 180)  # Longitude\n",
    "\n",
    "#Calculate distances\n",
    "gbr_distances = [\n",
    "    geodesic(actual, predicted).kilometers\n",
    "    for actual, predicted in zip(y_test.values, gbr_predictions)\n",
    "]\n",
    "\n",
    "#Data Frame for viewing\n",
    "results = pd.DataFrame({\n",
    "    'Actual Latitude': y_test['longitude'].values,\n",
    "    'Actual Longitude': y_test['latitude'].values,\n",
    "    'GBR Latitude': gbr_predictions[:, 0],\n",
    "    'GBR Longitude': gbr_predictions[:, 1],\n",
    "    'GBR Distance (km)': gbr_distances,\n",
    "})\n",
    "\n",
    "#Evaluate\n",
    "print(f\"Mean Distance Error: {np.mean(gbr_distances):.2f} km\")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ccd72410-a99c-4799-b92c-264ebe9e20cc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1059/1059 [09:36<00:00,  1.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             1         2         3         4         5         6         7  \\\n",
      "0     7.161286  7.835325  2.911583  0.984049 -1.499546 -2.094097  0.576000   \n",
      "1     0.225763 -0.094169 -0.603646  0.497745  0.874036  0.290280 -0.077659   \n",
      "2    -0.692525 -0.517801 -0.788035  1.214351 -0.907214  0.880213  0.406899   \n",
      "3    -0.735562 -0.684055  2.058215  0.716328 -0.011393  0.805396  1.497982   \n",
      "4     0.570272  0.273157 -0.279214  0.083456  1.049331 -0.869295 -0.265858   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "1054  0.399577  0.310805 -0.039326 -0.111546  0.304586 -0.943453  0.114960   \n",
      "1055  1.640386  1.306224  0.192745 -1.816855 -1.311906 -2.128963 -1.875967   \n",
      "1056 -0.772360 -0.670596 -0.840420 -0.832105  0.277346  1.152162  0.241470   \n",
      "1057 -0.996965 -1.099395  3.515274 -0.508185 -1.102654  0.192081  0.069821   \n",
      "1058 -0.150911 -0.094333 -0.568885 -0.614652  0.332477 -0.954948 -1.527722   \n",
      "\n",
      "             8         9        10  ...        63        64        65  \\\n",
      "0    -1.205671  1.849122 -0.425598  ... -1.018726 -0.174878 -1.089543   \n",
      "1    -0.887385  0.432062 -0.093963  ... -0.157861 -0.157189  0.380951   \n",
      "2    -0.694895 -0.901869 -1.701574  ...  0.217914  2.718442  0.972919   \n",
      "3     0.114752  0.692847  0.052377  ... -0.724247 -1.020687 -0.751380   \n",
      "4    -0.401676 -0.872639  1.147483  ... -0.820172 -0.190488  0.306974   \n",
      "...        ...       ...       ...  ...       ...       ...       ...   \n",
      "1054 -0.335898  0.826753 -0.393786  ... -0.106835  1.526307  0.646088   \n",
      "1055  0.094232 -1.429742  0.873777  ...  0.226782  0.182107  0.517466   \n",
      "1056  0.229092  0.019036 -0.068804  ... -0.590039 -0.804297  0.044170   \n",
      "1057  0.264674 -0.411533  0.501164  ...  0.738616  1.240377 -0.546002   \n",
      "1058 -1.591471 -3.678713 -5.930209  ...  3.673086  0.960420  1.067164   \n",
      "\n",
      "            66        67        68  longitude  latitude  Cluster     country  \n",
      "0    -0.668840 -0.914772 -0.836250     -15.75    -47.95        4      Brazil  \n",
      "1     1.088478 -0.123595  1.391141      14.91    -23.51        1  Cape Verde  \n",
      "2     2.081069  1.375763  1.063847      12.65     -8.00        1        Mali  \n",
      "3    -0.385005 -0.012326 -0.392197       9.03     38.74        5    Ethiopia  \n",
      "4     0.119658  0.271838  1.289783      34.03     -6.85        1     Morocco  \n",
      "...        ...       ...       ...        ...       ...      ...         ...  \n",
      "1054  2.467278  1.867699  1.719302      -6.17     35.74        5    Tanzania  \n",
      "1055  1.126762  2.220671  4.422651      11.55    104.91        0    Cambodia  \n",
      "1056 -0.718175 -0.983640 -0.573822      41.33     19.80        3     Albania  \n",
      "1057 -0.137473 -0.781036 -0.832167      54.68     25.31        3   Lithuania  \n",
      "1058  5.244305  2.506568  1.462580      54.68     25.31        3   Lithuania  \n",
      "\n",
      "[1059 rows x 72 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Reverse Geo-locate to get Country and add to df\n",
    "\n",
    "#import saved df because this took forever to run. Can be downloaded via GitHub\n",
    "newdf = pd.read_csv('MusicDataWCountry.csv', delimiter=',') \n",
    "\n",
    "################################################################################\n",
    "geolocator = Nominatim(user_agent=\"myapp\")\n",
    "\n",
    "#Pull address from coords and country name from address\n",
    "def get_country(lat, lon):\n",
    "    try:\n",
    "        location = geolocator.reverse((lat, lon), language='en')\n",
    "        if location and 'country' in location.raw['address']:\n",
    "            return location.raw['address']['country']\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error for coordinates ({lat}, {lon}): {e}\")\n",
    "        return None\n",
    "\n",
    "#Add to df with progress bar for sanity\n",
    "tqdm.pandas() \n",
    "newdf['country'] = df.progress_apply(lambda row: get_country(row['longitude'], row['latitude']), axis=1)\n",
    "\n",
    "print(newdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1622d935-9752-4029-b95a-4849e3322088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster                                                  0  \\\n",
      "country  [Turkey, Egypt, Algeria, Senegal, Kyrgyzstan, ...   \n",
      "\n",
      "Cluster                                                  1  \\\n",
      "country  [Lithuania, Algeria, Ethiopia, Thailand, China...   \n",
      "\n",
      "Cluster                                                  2  \\\n",
      "country  [Brazil, Cape Verde, Mali, Ethiopia, Morocco, ...   \n",
      "\n",
      "Cluster                                                  3  \\\n",
      "country  [Uzbekistan, Algeria, Romania, United Kingdom,...   \n",
      "\n",
      "Cluster                                                  4  \\\n",
      "country  [Mali, Kyrgyzstan, Kenya, Iran, India, Italy, ...   \n",
      "\n",
      "Cluster                                                  5  \\\n",
      "country  [Mali, Uzbekistan, Kenya, Greece, Brazil, Cape...   \n",
      "\n",
      "Cluster                                                  6  \n",
      "country  [Albania, Egypt, Myanmar, Lithuania, Brazil, I...  \n"
     ]
    }
   ],
   "source": [
    "#saving so I only have to do that ^ once\n",
    "#newdf.to_csv('MusicDataWCountry.csv')\n",
    "\n",
    "#K Means Clustering\n",
    "num_clusters = 7\n",
    "\n",
    "#Specify and predict\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=77)\n",
    "cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "#Add to df\n",
    "newdf['Cluster'] = cluster_labels\n",
    "\n",
    "#Remove any duplicates\n",
    "unique_df = newdf[['country', 'Cluster']].drop_duplicates()\n",
    "\n",
    "#Make table to compare clusters\n",
    "cluster_table = unique_df.groupby('Cluster')['country'].apply(list).reset_index()\n",
    "cluster_table = cluster_table.set_index('Cluster').T\n",
    "print(cluster_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "acf1ab63-f60b-492c-a7e1-534418eec251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.44\n",
      "Confusion Matrix:\n",
      "[[3 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 2 0 0]\n",
      " [0 0 1 ... 0 0 1]\n",
      " ...\n",
      " [0 0 0 ... 5 0 1]\n",
      " [0 0 0 ... 0 7 0]\n",
      " [0 1 0 ... 0 0 2]]\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Albania       0.50      0.60      0.55         5\n",
      "       Algeria       0.17      0.25      0.20         8\n",
      "     Australia       0.25      0.50      0.33         2\n",
      "        Belize       0.50      0.50      0.50         2\n",
      "        Brazil       0.17      0.25      0.20         4\n",
      "      Cambodia       1.00      1.00      1.00         4\n",
      "    Cape Verde       0.00      0.00      0.00         2\n",
      "         China       0.40      0.22      0.29         9\n",
      "         Egypt       0.00      0.00      0.00         9\n",
      "      Ethiopia       0.60      0.25      0.35        12\n",
      "       Georgia       0.60      1.00      0.75         6\n",
      "        Greece       0.75      0.50      0.60         6\n",
      "         India       0.15      0.30      0.20        10\n",
      "     Indonesia       0.00      0.00      0.00         5\n",
      "          Iran       0.00      0.00      0.00         4\n",
      "         Italy       0.38      0.45      0.42        11\n",
      "       Jamaica       0.57      0.80      0.67         5\n",
      "         Japan       0.00      0.00      0.00         7\n",
      "         Kenya       0.83      0.45      0.59        11\n",
      "    Kyrgyzstan       0.50      0.75      0.60         4\n",
      "     Lithuania       0.57      0.80      0.67         5\n",
      "          Mali       0.35      0.55      0.43        11\n",
      "       Morocco       0.67      0.57      0.62         7\n",
      "       Myanmar       0.50      1.00      0.67         6\n",
      "      Pakistan       0.14      0.11      0.12         9\n",
      "       Romania       1.00      0.25      0.40         4\n",
      "       Senegal       0.33      0.20      0.25         5\n",
      "        Taiwan       0.86      1.00      0.92         6\n",
      "      Tanzania       0.67      0.50      0.57         4\n",
      "      Thailand       0.50      0.33      0.40         3\n",
      "        Turkey       0.50      0.45      0.48        11\n",
      "United Kingdom       0.88      1.00      0.93         7\n",
      "    Uzbekistan       0.29      0.29      0.29         7\n",
      "\n",
      "      accuracy                           0.44       211\n",
      "     macro avg       0.44      0.45      0.42       211\n",
      "  weighted avg       0.44      0.44      0.42       211\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shsma\\OneDrive\\Documents\\ML Class\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\shsma\\OneDrive\\Documents\\ML Class\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\shsma\\OneDrive\\Documents\\ML Class\\venv\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "#Decision Tree Classification\n",
    "\n",
    "#Split new df for new target and get rid of coords bc overfitting\n",
    "X = newdf.drop(['longitude', 'latitude','country'], axis=1)\n",
    "y = newdf['country']\n",
    "\n",
    "#K Folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=77)\n",
    "for train_index, test_index in kf.split(X, y):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]    \n",
    "\n",
    "#Specify classifier\n",
    "classifier = RandomForestClassifier(random_state=77, n_estimators = 100)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "#Predict\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "#Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
